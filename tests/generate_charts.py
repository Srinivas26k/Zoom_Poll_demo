"""
Chart generation script for test metrics visualization

This script reads the CSV files generated by the test_metrics_analyzer
and creates charts suitable for inclusion in documentation.

Requires matplotlib, pandas, and seaborn.
"""
import os
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import argparse
from pathlib import Path
import datetime

# Set the style
plt.style.use('ggplot')
sns.set_theme(style="whitegrid")

def ensure_output_dir(output_dir):
    """Ensure the output directory exists"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    return output_path

def generate_test_summary_chart(data_dir, output_dir):
    """Generate pie chart of test results"""
    # Load the summary data
    summary_file = os.path.join(data_dir, "summary_stats.csv")
    if not os.path.exists(summary_file):
        print(f"Warning: {summary_file} not found. Skipping test summary chart.")
        return None
    
    summary_df = pd.read_csv(summary_file)
    
    # Convert to dictionary for easier access
    summary_dict = dict(zip(summary_df['Metric'], summary_df['Value']))
    
    # Get test status counts
    test_statuses = {
        'Passed': float(summary_dict.get('Passed Tests', 0)),
        'Failed': float(summary_dict.get('Failed Tests', 0)),
        'Skipped': float(summary_dict.get('Skipped Tests', 0)),
        'Error': float(summary_dict.get('Error Tests', 0))
    }
    
    # Remove zeros
    test_statuses = {k: v for k, v in test_statuses.items() if v > 0}
    
    # Create the pie chart
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # Color mapping
    colors = {
        'Passed': '#4CAF50',  # Green
        'Failed': '#F44336',  # Red
        'Skipped': '#FFC107',  # Amber
        'Error': '#9C27B0',   # Purple
    }
    
    status_colors = [colors[status] for status in test_statuses.keys()]
    
    # Plot
    wedges, texts, autotexts = ax.pie(
        test_statuses.values(), 
        labels=test_statuses.keys(),
        autopct='%1.1f%%',
        startangle=90,
        colors=status_colors
    )
    
    # Style
    plt.setp(autotexts, size=10, weight="bold")
    plt.setp(texts, size=12)
    
    # Title with pass rate
    pass_rate = float(summary_dict.get('Pass Rate (%)', 0))
    ax.set_title(f'Test Results - {pass_rate:.1f}% Pass Rate', fontsize=16)
    
    # Save the chart
    output_file = os.path.join(output_dir, "test_summary_pie.png")
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close()
    
    return output_file

def generate_performance_bar_chart(data_dir, output_dir):
    """Generate bar chart of test performance by type"""
    # Load the performance data
    perf_file = os.path.join(data_dir, "performance_metrics.csv")
    if not os.path.exists(perf_file):
        print(f"Warning: {perf_file} not found. Skipping performance bar chart.")
        return None
    
    perf_df = pd.read_csv(perf_file)
    
    # Convert durations to float
    numeric_cols = ['Min Duration (s)', 'Max Duration (s)', 'Avg Duration (s)', 
                    'Median Duration (s)', 'Total Duration (s)']
    for col in numeric_cols:
        perf_df[col] = perf_df[col].astype(float)
    
    # Create the bar chart
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Use a custom color palette
    colors = sns.color_palette("muted", len(perf_df))
    
    # Plot average duration by test type
    bars = ax.bar(
        perf_df['Test Type'], 
        perf_df['Avg Duration (s)'],
        yerr=perf_df['Max Duration (s)'] - perf_df['Min Duration (s)'],
        capsize=10,
        color=colors,
        alpha=0.7
    )
    
    # Add test count annotations
    for i, bar in enumerate(bars):
        count = perf_df.iloc[i]['Test Count']
        height = bar.get_height()
        ax.text(
            bar.get_x() + bar.get_width()/2.,
            height + 0.02,
            f'{count} tests',
            ha='center', 
            va='bottom',
            fontweight='bold'
        )
    
    # Style
    ax.set_ylabel('Average Duration (seconds)', fontsize=12)
    ax.set_xlabel('Test Type', fontsize=12)
    ax.set_title('Test Performance by Type', fontsize=16)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    
    # Save the chart
    output_file = os.path.join(output_dir, "performance_by_type.png")
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close()
    
    return output_file

def generate_memory_usage_chart(data_dir, output_dir):
    """Generate line chart of memory usage during test execution"""
    # Load the memory data
    memory_file = os.path.join(data_dir, "memory_usage.csv")
    if not os.path.exists(memory_file):
        print(f"Warning: {memory_file} not found. Skipping memory usage chart.")
        return None
    
    memory_df = pd.read_csv(memory_file)
    
    # Convert memory to float
    memory_df['Memory (MB)'] = memory_df['Memory (MB)'].astype(float)
    
    # Sort by timestamp
    memory_df['Timestamp'] = memory_df['Timestamp'].astype(float)
    memory_df = memory_df.sort_values('Timestamp')
    
    # Create a sequence number for x-axis
    memory_df['Sequence'] = range(len(memory_df))
    
    # Create the line chart
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Plot memory usage over time
    ax.plot(
        memory_df['Sequence'], 
        memory_df['Memory (MB)'],
        marker='o',
        markersize=4,
        linestyle='-',
        linewidth=2,
        color='#2196F3',
        alpha=0.7
    )
    
    # Add a trend line
    z = np.polyfit(memory_df['Sequence'], memory_df['Memory (MB)'], 1)
    p = np.poly1d(z)
    ax.plot(
        memory_df['Sequence'],
        p(memory_df['Sequence']),
        "r--", 
        linewidth=1,
        alpha=0.8
    )
    
    # Style
    ax.set_ylabel('Memory Usage (MB)', fontsize=12)
    ax.set_xlabel('Test Sequence', fontsize=12)
    ax.set_title('Memory Usage During Test Execution', fontsize=16)
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Annotate min and max
    min_idx = memory_df['Memory (MB)'].idxmin()
    max_idx = memory_df['Memory (MB)'].idxmax()
    
    ax.annotate(
        f'Min: {memory_df.loc[min_idx, "Memory (MB)"]:.1f} MB',
        xy=(memory_df.loc[min_idx, 'Sequence'], memory_df.loc[min_idx, 'Memory (MB)']),
        xytext=(10, -30),
        textcoords='offset points',
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2')
    )
    
    ax.annotate(
        f'Max: {memory_df.loc[max_idx, "Memory (MB)"]:.1f} MB',
        xy=(memory_df.loc[max_idx, 'Sequence'], memory_df.loc[max_idx, 'Memory (MB)']),
        xytext=(10, 30),
        textcoords='offset points',
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2')
    )
    
    # Save the chart
    output_file = os.path.join(output_dir, "memory_usage.png")
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close()
    
    return output_file

def generate_test_duration_distribution(data_dir, output_dir):
    """Generate histogram of test durations"""
    # Load the test details data
    details_file = os.path.join(data_dir, "test_details.csv")
    if not os.path.exists(details_file):
        print(f"Warning: {details_file} not found. Skipping test duration distribution chart.")
        return None
    
    details_df = pd.read_csv(details_file)
    
    # Convert duration to float
    details_df['Duration (s)'] = details_df['Duration (s)'].astype(float)
    
    # Create the histogram
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Group by test type
    test_types = details_df['Test Type'].unique()
    
    # Plot histograms for each test type
    for test_type in test_types:
        subset = details_df[details_df['Test Type'] == test_type]
        sns.histplot(
            data=subset,
            x='Duration (s)',
            label=test_type,
            alpha=0.6,
            kde=True,
            ax=ax
        )
    
    # Style
    ax.set_xlabel('Test Duration (seconds)', fontsize=12)
    ax.set_ylabel('Count', fontsize=12)
    ax.set_title('Distribution of Test Durations by Type', fontsize=16)
    ax.legend(title='Test Type')
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Save the chart
    output_file = os.path.join(output_dir, "test_duration_distribution.png")
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close()
    
    return output_file

def generate_pass_fail_by_type(data_dir, output_dir):
    """Generate stacked bar chart of pass/fail by test type"""
    # Load the test details data
    details_file = os.path.join(data_dir, "test_details.csv")
    if not os.path.exists(details_file):
        print(f"Warning: {details_file} not found. Skipping pass/fail by type chart.")
        return None
    
    details_df = pd.read_csv(details_file)
    
    # Group by test type and outcome
    outcome_counts = details_df.groupby(['Test Type', 'Outcome']).size().unstack(fill_value=0)
    
    # Create the stacked bar chart
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Plot the stacked bars
    outcome_counts.plot(
        kind='bar',
        stacked=True,
        ax=ax,
        color={
            'passed': '#4CAF50',  # Green
            'failed': '#F44336',  # Red
            'skipped': '#FFC107', # Amber
            'error': '#9C27B0',   # Purple
        }
    )
    
    # Style
    ax.set_xlabel('Test Type', fontsize=12)
    ax.set_ylabel('Count', fontsize=12)
    ax.set_title('Test Outcomes by Type', fontsize=16)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    
    # Add a table below the chart with percentages
    rows = []
    columns = ['Test Type', 'Total', 'Passed', 'Failed', 'Pass Rate']
    
    for test_type in outcome_counts.index:
        total = outcome_counts.loc[test_type].sum()
        passed = outcome_counts.loc[test_type].get('passed', 0)
        failed = outcome_counts.loc[test_type].get('failed', 0)
        pass_rate = (passed / total * 100) if total > 0 else 0
        
        rows.append([test_type, total, passed, failed, f"{pass_rate:.1f}%"])
    
    # Add table to the bottom of the chart
    table_data = [columns] + rows
    table = ax.table(
        cellText=rows,
        colLabels=columns,
        loc='bottom',
        cellLoc='center',
        bbox=[0, -0.3, 1, 0.2]
    )
    
    # Adjust layout to make room for the table
    plt.subplots_adjust(bottom=0.3)
    
    # Save the chart
    output_file = os.path.join(output_dir, "test_outcome_by_type.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    return output_file

def generate_all_charts(data_dir, output_dir):
    """Generate all charts from test metrics data"""
    import numpy as np
    
    output_dir = ensure_output_dir(output_dir)
    
    # Generate each chart
    summary_chart = generate_test_summary_chart(data_dir, output_dir)
    performance_chart = generate_performance_bar_chart(data_dir, output_dir)
    memory_chart = generate_memory_usage_chart(data_dir, output_dir)
    duration_dist = generate_test_duration_distribution(data_dir, output_dir)
    outcome_chart = generate_pass_fail_by_type(data_dir, output_dir)
    
    # Print results
    print("\nCharts generated:")
    for chart in [summary_chart, performance_chart, memory_chart, 
                 duration_dist, outcome_chart]:
        if chart:
            print(f"- {chart}")
    
    return {
        "summary": summary_chart,
        "performance": performance_chart,
        "memory": memory_chart,
        "duration": duration_dist,
        "outcome": outcome_chart
    }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate charts from test metrics data")
    parser.add_argument("--data-dir", default="test-reports/chart-data", 
                        help="Directory containing CSV data files")
    parser.add_argument("--output-dir", default="test-reports/charts", 
                        help="Output directory for charts")
    
    args = parser.parse_args()
    generate_all_charts(args.data_dir, args.output_dir) 